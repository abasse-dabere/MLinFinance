{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e6a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a6336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloner le dépôt officiel\n",
    "# !git clone https://github.com/gregzanotti/dlsa-public.git\n",
    "\n",
    "# Installer les dépendances\n",
    "# %cd dlsa-public\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Commenter les lignes contenant 'plt' dans dlsa-public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953e394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041d0a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilisé : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device utilisé : {device}\")\n",
    "\n",
    "# free GPU memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7655de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f864165",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = 'dlsa-public/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7969a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6de10ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CNNTransformer import CNNTransformer\n",
    "from models.FourierFFN import FourierFFN\n",
    "from models.OUFFN import OUFFN\n",
    "from preprocess import preprocess_cumsum, preprocess_fourier, preprocess_ou\n",
    "from train_test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2a0166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger les données de résidus à partir du dépôt (si disponibles)\n",
    "def load_residual_data(gz_path):\n",
    "    \"\"\"\n",
    "    Tente de charger des données résiduelles pré-calculées du dépôt.\n",
    "    Retourne (data_array, dates_index, resid_series) ou (None, None, None) si non disponible.\n",
    "    \"\"\"\n",
    "    # Chemin du fichier numpy des résidus (exemple avec modèle Fama-French 5 facteurs)\n",
    "    filepath = gz_path[:-3]  # Enlève l'extension .gz\n",
    "    if os.path.exists(filepath) or os.path.exists(gz_path):\n",
    "        # Décompresser si nécessaire\n",
    "        if not os.path.exists(filepath) and os.path.exists(gz_path):\n",
    "            import gzip, shutil\n",
    "            with gzip.open(gz_path, 'rb') as f_in:\n",
    "                with open(filepath, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "        # Charger les données numpy\n",
    "        residuals = np.load(filepath).astype(np.float32)\n",
    "        T = residuals.shape[0]\n",
    "        # Générer un index de dates pour T jours ouvrés à partir du 01/01/1998 (approximation)\n",
    "        dates = pd.bdate_range(start=\"1998-01-01\", periods=T)\n",
    "        # Calculer la série cumulée du premier résidu pour la stratégie OU+Threshold\n",
    "        if residuals.ndim > 1:\n",
    "            resid_series = np.cumsum(residuals[:, 0])\n",
    "        else:\n",
    "            resid_series = np.cumsum(residuals)\n",
    "        return residuals, dates, resid_series\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522b7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour exécuter et évaluer une stratégie deep learning (CNN+Transformer ou Fourier+NN)\n",
    "def run_deep_strategy(name, model_class, preprocess_func, data, dates, config):\n",
    "    \"\"\"\n",
    "    Entraîne et teste la stratégie de trading spécifiée (model_class avec preprocess_func) sur les données fournies.\n",
    "    Renvoie un dict contenant les métriques de performance et les rendements journaliers.\n",
    "    \"\"\"\n",
    "    cfg = config.copy()\n",
    "    # Exécuter la simulation train/test\n",
    "    rets, sharpe, ret, std, turnover, short_prop = test(\n",
    "        data,\n",
    "        dates,\n",
    "        model_class,\n",
    "        preprocess_func,\n",
    "        cfg,\n",
    "        residual_weights=None,\n",
    "        save_params=False,\n",
    "        force_retrain=cfg['force_retrain'],\n",
    "        parallelize=False,\n",
    "        device='cuda',\n",
    "        output_path=\".\",\n",
    "        log_dev_progress_freq=50,\n",
    "        log_plot_freq=50,\n",
    "        num_epochs=cfg['num_epochs'],\n",
    "        early_stopping=cfg['early_stopping'],\n",
    "        batchsize=cfg['batch_size'],\n",
    "        retrain_freq=cfg['retrain_freq'],\n",
    "        rolling_retrain=cfg['rolling_retrain'],\n",
    "        length_training=cfg['length_training'],\n",
    "        lookback=cfg['model']['lookback'],\n",
    "        trans_cost=cfg['trans_cost'],\n",
    "        hold_cost=cfg['hold_cost'],\n",
    "        objective=cfg['objective'],\n",
    "        model_tag=name\n",
    "    )\n",
    "    # Calculer les métriques\n",
    "    mean_daily_ret = float(ret)      # rendement moyen quotidien (non annualisé)\n",
    "    daily_vol = float(std)           # volatilité quotidienne\n",
    "    daily_sharpe = float(sharpe)     # Sharpe ratio quotidien (mean/std)\n",
    "    ann_ret = mean_daily_ret * 252.0 if daily_vol != 0 else 0.0\n",
    "    ann_vol = daily_vol * np.sqrt(252.0)\n",
    "    ann_sharpe = daily_sharpe * np.sqrt(252.0) if daily_vol != 0 else 0.0\n",
    "    # Générer et sauvegarder les graphiques\n",
    "    out_dates = dates[-len(rets):]  # dates correspondantes à la période test\n",
    "    cum_returns = np.cumprod(1 + rets)\n",
    "    # Résultats\n",
    "    return {\n",
    "        'annual_return': ann_ret,\n",
    "        'annual_volatility': ann_vol,\n",
    "        'sharpe_ratio': ann_sharpe,\n",
    "        'daily_returns': rets,\n",
    "        'cumulative_returns': cum_returns,\n",
    "        'dates': out_dates\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour exécuter et évaluer la stratégie OU + Threshold\n",
    "def run_threshold_strategy(name, resid_series, dates, config, threshold_coef=2.0):\n",
    "    \"\"\"\n",
    "    Simule une stratégie de retour à la moyenne avec seuil sur la série résiduelle fournie.\n",
    "    Entrée longue si le résidu < -seuil, entrée courte si résidu > +seuil, sortie de position quand le résidu repasse par 0.\n",
    "    Renvoie un dict contenant les métriques de performance et les rendements journaliers.\n",
    "    \"\"\"\n",
    "    T = len(resid_series)\n",
    "    train_len = config.get('length_training', int(T * 0.5))\n",
    "    train_len = min(train_len, T - 1)\n",
    "    # Calibrer le seuil sur la période d'entraînement\n",
    "    std_train = float(np.std(resid_series[:train_len]))\n",
    "    threshold = threshold_coef * std_train\n",
    "    pos = 0  # position courante (1 = long résidu, -1 = short résidu)\n",
    "    prev_resid = resid_series[train_len - 1]\n",
    "    returns_list = []\n",
    "    for t in range(train_len, T):\n",
    "        if t > train_len:\n",
    "            # P&L du jour t (différence du résidu multipliée par la position détenue)\n",
    "            pnl = pos * (resid_series[t] - prev_resid)\n",
    "            returns_list.append(pnl)\n",
    "        # Mettre à jour la position à la fin du jour t\n",
    "        if pos == 0:\n",
    "            if resid_series[t] > threshold:\n",
    "                pos = -1  # résidu haut -> vendre\n",
    "            elif resid_series[t] < -threshold:\n",
    "                pos = 1   # résidu bas -> acheter\n",
    "        elif pos == 1:\n",
    "            if resid_series[t] >= 0:\n",
    "                pos = 0   # clôturer la position longue\n",
    "        elif pos == -1:\n",
    "            if resid_series[t] <= 0:\n",
    "                pos = 0   # clôturer la position courte\n",
    "        prev_resid = resid_series[t]\n",
    "    returns = np.array(returns_list, dtype=np.float32)\n",
    "    test_dates = dates[-len(returns):] if len(returns) < len(dates) else dates[train_len+1:]\n",
    "    # Calcul des métriques\n",
    "    mean_daily_ret = returns.mean() if returns.size > 0 else 0.0\n",
    "    daily_vol = returns.std(ddof=0) if returns.size > 0 else 0.0\n",
    "    daily_sharpe = mean_daily_ret/daily_vol if daily_vol != 0 else 0.0\n",
    "    ann_ret = mean_daily_ret * 252.0 if daily_vol != 0 else 0.0\n",
    "    ann_vol = daily_vol * np.sqrt(252.0)\n",
    "    ann_sharpe = daily_sharpe * np.sqrt(252.0) if daily_vol != 0 else 0.0\n",
    "    cum_returns = np.cumprod(1 + returns)\n",
    "    # Résultats\n",
    "    return {\n",
    "        'annual_return': ann_ret,\n",
    "        'annual_volatility': ann_vol,\n",
    "        'sharpe_ratio': ann_sharpe,\n",
    "        'daily_returns': returns,\n",
    "        'cumulative_returns': cum_returns,\n",
    "        'dates': test_dates\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "184e77ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de jours de données : 4781, Nombre de séries résiduelles : 9483\n",
      "Réduction : utilisation de seulement 5000 résidus.\n"
     ]
    }
   ],
   "source": [
    "# Charger les données de résidus\n",
    "residual_data_name = \"AvPCA_OOSresiduals_3_factors_1998_initialOOSYear_60_rollingWindow_252_covWindow_0.01_Cap.npy\"\n",
    "gz_path = os.path.join(repo_path, \"residuals\", \"pca\", residual_data_name + \".gz\")\n",
    "data, dates, resid_series = load_residual_data(gz_path)\n",
    "\n",
    "# S'assurer que data est un tableau 2D numpy (T x N)\n",
    "T = data.shape[0]\n",
    "if data.ndim == 1:\n",
    "    data = data.reshape(-1, 1)\n",
    "N = data.shape[1]\n",
    "print(f\"Nombre de jours de données : {T}, Nombre de séries résiduelles : {N}\")\n",
    "\n",
    "# Définir la longueur de la période d'entraînement initiale (length_training)\n",
    "length_training = 1000\n",
    "if T <= length_training:\n",
    "    length_training = max(int(T * 0.5), 1)\n",
    "length_training = min(length_training, T - 1)  # au moins 1 jour de test\n",
    "\n",
    "# Après avoir chargé les résidus\n",
    "if data.shape[1] > 5000:\n",
    "    data = data[:, :5000]\n",
    "    print(f\"Réduction : utilisation de seulement {data.shape[1]} résidus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb62b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration commune pour les stratégies deep learning\n",
    "config = {\n",
    "    'model': {'lookback': 30},\n",
    "    'force_retrain': True,\n",
    "    'early_stopping': False,\n",
    "    'rolling_retrain': True,\n",
    "    'retrain_freq': 250,\n",
    "    'length_training': length_training,\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 512,\n",
    "    'optimizer_name': 'Adam',\n",
    "    'optimizer_opts': {'lr': 0.001},\n",
    "    'trans_cost': 0.0,\n",
    "    'hold_cost': 0.0,\n",
    "    'objective': 'sharpe',\n",
    "    'mode': 'test',\n",
    "    'debug': False,\n",
    "    'results_tag': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029c00f",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0feee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exécution de la stratégie CNN+Transformer...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExécution de la stratégie CNN+Transformer...\")\n",
    "strategies_results1 = run_deep_strategy('CNNTransformer', CNNTransformer, preprocess_cumsum, data, dates, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "379dfc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_results1 = {\n",
    "    'annual_return': strategies_results1['annual_return'],\n",
    "    'annual_volatility': strategies_results1['annual_volatility'],\n",
    "    'sharpe_ratio': strategies_results1['sharpe_ratio'],\n",
    "    'daily_returns': strategies_results1['daily_returns'].tolist(),\n",
    "    'cumulative_returns': strategies_results1['cumulative_returns'].tolist(),\n",
    "    'dates': [str(d).split()[0] for d in strategies_results1['dates']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the json file\n",
    "import json\n",
    "with open(f'results/{residual_data_name[:-4]}_CNN+Transformer_results.json', 'w') as f:\n",
    "    json.dump(strategies_results1, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7031d9",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc7b4496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exécution de la stratégie Fourier+NN...\n"
     ]
    }
   ],
   "source": [
    "# Stratégie 2 : Fourier + NN\n",
    "print(\"\\nExécution de la stratégie Fourier+NN...\")\n",
    "strategies_results2 = run_deep_strategy('FourierFFN', FourierFFN, preprocess_fourier, data, dates, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d35642",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_results2 = {\n",
    "    'annual_return': strategies_results2['annual_return'],\n",
    "    'annual_volatility': strategies_results2['annual_volatility'],\n",
    "    'sharpe_ratio': strategies_results2['sharpe_ratio'],\n",
    "    'daily_returns': strategies_results2['daily_returns'].tolist(),\n",
    "    'cumulative_returns': strategies_results2['cumulative_returns'].tolist(),\n",
    "    'dates': [str(d).split()[0] for d in strategies_results2['dates']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8429762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the json file\n",
    "import json\n",
    "with open(f'results/{residual_data_name[:-4]}_Fourier+NN_results.json', 'w') as f:\n",
    "    json.dump(strategies_results2, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa4da6",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
